{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Article classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Вот и настал момент, который, наверно, ждали многие! Сейчас мы попробуем обучить простую модель для классификации статей. Во многом это туториал вдохновлен <a href=\"http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\">этими материалами</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Обучающая выборка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала нам необходимо раздобыть обучающую выборку. Мы воспользуемся готовой коллекцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: the 20 newsgroups by date dataset\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "dataset = sklearn.datasets.fetch_20newsgroups(subset='all', data_home='data')\n",
    "print('Description:', dataset['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из описания, данные представляют собой список новостных статей, разбитых на 20 тем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:\n",
      "1. alt.atheism\n",
      "2. comp.graphics\n",
      "3. comp.os.ms-windows.misc\n",
      "4. comp.sys.ibm.pc.hardware\n",
      "5. comp.sys.mac.hardware\n",
      "6. comp.windows.x\n",
      "7. misc.forsale\n",
      "8. rec.autos\n",
      "9. rec.motorcycles\n",
      "10. rec.sport.baseball\n",
      "11. rec.sport.hockey\n",
      "12. sci.crypt\n",
      "13. sci.electronics\n",
      "14. sci.med\n",
      "15. sci.space\n",
      "16. soc.religion.christian\n",
      "17. talk.politics.guns\n",
      "18. talk.politics.mideast\n",
      "19. talk.politics.misc\n",
      "20. talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "topics = dataset['target_names']\n",
    "print('Topics:')\n",
    "for pair in enumerate(topics, 1):\n",
    "    print('%i. %s' % pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Но мы хотим научиться решать задачу бинарной классификации. И предсказывать вероятность, что статья нам понравится. Поэтому обсуловимся, что все статьи с темой наука и компьютеры нам интересны, а остальные нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interesting, boring = set(), set()\n",
    "for i, topic in enumerate(topics):\n",
    "    if topic.startswith('sci.') or topic.startswith('comp.'):\n",
    "        interesting.add(i)\n",
    "    else:\n",
    "        boring.add(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько у нас всего статей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n"
     ]
    }
   ],
   "source": [
    "data = dataset['data']\n",
    "N = len(data)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Теперь нам надо позаботиться об извлечении признаков из текста. Посмотрим, как выглядит случайная статья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: nlu@Xenon.Stanford.EDU (Nelson Lu)\n",
      "Subject: Re: Why is Barry Bonds not batting 4th?\n",
      "Organization: Computer Science Department, Stanford University.\n",
      "Lines: 37\n",
      "\n",
      "In article <1r93di$car@apple.com> chuq@apple.com (Chuq Von Rospach) writes:\n",
      ">punjabi@leland.Stanford.EDU (sanjeev punjabi) writes:\n",
      ">\n",
      ">>Some evidence that is NOT working:\n",
      ">\n",
      ">Take a look at the standings. It's REAL easy to get so focussed on \n",
      ">minutinae and forget that the Giants happen to be in first place. If it's\n",
      ">working, you don't SCREW IT UP by changing things, just because you think it\n",
      ">ought to be different.\n",
      "\n",
      "So, that is the reason why the Toronto Blue Jays *should* keep Alfredo\n",
      "Griffin, just because it \"worked\"?\n",
      "\n",
      "A team winning doesn't mean that everything that it's doing is right.\n",
      "A team not winning doesn't mean that everything that it's doing is wrong, or\n",
      "otherwise (to borrow the Sharks' situation) you would say that George Kingston\n",
      "should be fired.\n",
      "\n",
      ">Some folks like to argue about theoretical details. I prefer to watch teams\n",
      ">win. When the Giants slip to third, then we can talk about how to re-arrange\n",
      ">the batting order. Until then, I think it's stupid to focus on what's wrong,\n",
      ">for the simple fact that IT'S WORKING AS IT IS.\n",
      "\n",
      "By then, it's too late.  The problem with \"not fixing something while it's\n",
      "working\" is that by then, there may not be anything left to fix.\n",
      "\n",
      ">Mostly, though, the Giants are winning, and frankly, as long as that\n",
      ">continues, it's rather silly to second-guess their strategy. But evidently,\n",
      ">some folks would rather be right than be first.\n",
      "\n",
      "So, the Blue Jays were simply perfect last year; there was nothing that they\n",
      "could have done to have improved that team.  NOT.\n",
      "\n",
      "===============================================================================\n",
      "GO CALIFORNIA ANGELS!\n",
      "===============================================================================\n",
      "Nelson Lu (claudius@leland.stanford.edu)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = dataset['data'][random.randint(0, N - 1)]\n",
    "for line in article.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Мы видим, что это достаточно грязный текст. Это значит, что для извлечения слова нам потребуются регулярные выражения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы выберем самый простой шаблон. Слово -- это просто непрерывная последовательность букв. Кстати, для простоты сделаем все буквы в тексте маленькими."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD_PATTERN = '[a-z]+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получится. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from\n",
      "nlu\n",
      "xenon\n",
      "stanford\n",
      "edu\n",
      "nelson\n",
      "lu\n",
      "subject\n",
      "re\n",
      "why\n",
      "is\n",
      "barry\n",
      "bonds\n",
      "not\n",
      "batting\n",
      "th\n",
      "organization\n",
      "computer\n",
      "science\n",
      "department\n"
     ]
    }
   ],
   "source": [
    "first_20_words = re.findall(WORD_PATTERN, article.lower())[:20]\n",
    "for word in first_20_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, встречается некоторый мусор, но в целом не так плохо. Теперь нам необходимо получить матрицу с признаками. Для этого мы воспользуемся уже готовым <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn-feature-extraction-text-countvectorizer\">классом</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать запуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(token_pattern=WORD_PATTERN)\n",
    "X = vectorizer.fit_transform(dataset['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результатом работы является матрица <a href=\"http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix\">типа</a>, с размерностью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 115065)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам необходимо подготовить метки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = numpy.array([1 if t in interesting else 0 for t in dataset['target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Линейный классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим нашу выборку на две части и сделаем пробное обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "border = 15000\n",
    "\n",
    "X_train, X_test = X[:border], X[border:]\n",
    "Y_train, Y_test = Y[:border], Y[border:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения сначала возьмем\n",
    "<a href=\"http://www.machinelearning.ru/wiki/index.php?title=Логистическая_регрессия\">логистическую регрессию</a>\n",
    "со стандартными настройками, которая обучается с помощью\n",
    "<a href=\"http://www.machinelearning.ru/wiki/index.php?title=Метод_градиентного_спуска\">градиентного спуска</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что у нас получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = sklearn.linear_model.SGDClassifier(loss='log')\n",
    "cls.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики качества будем использовать <a href=\"http://www.machinelearning.ru/wiki/index.php?title=ROC-кривая\">AUC</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какого качества мы достигли, проделав такие простые шаги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.98850517202\n"
     ]
    }
   ],
   "source": [
    "metric = sklearn.metrics.roc_auc_score\n",
    "\n",
    "Y_pred = cls.predict_proba(X_test)[:, 1]\n",
    "\n",
    "score = metric(Y_test, Y_pred)\n",
    "print('Score: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы попробовали обучить классификатор и даже определили качество его работы. Попробуем его улучшить, настроив внешнии парамтеры модели с помощью кроссвалидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого надо определить кое-что поднастроить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scorer(estimator, X, Y):\n",
    "    return metric(Y, estimator.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим сетку поиска параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'penalty': ['elasticnet'],\n",
    "    'alpha': [0.001, 0.0001, 0.00001, 0.000001, 0.0000001],\n",
    "    'l1_ratio': [0.0, 0.01, 0.05, 0.10, 0.2, 0.3, 0.4, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все подготовим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searcher = sklearn.grid_search.GridSearchCV(\n",
    "    estimator = sklearn.linear_model.SGDClassifier(loss='log'),\n",
    "    param_grid = grid,\n",
    "    scoring = scorer,\n",
    "    cv = 5,\n",
    "    n_jobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь надо немного подождать..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searcher.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994259001165\n",
      "{'alpha': 1e-05, 'l1_ratio': 0.0, 'penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "print(searcher.best_score_)\n",
    "print(searcher.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь проверим качествао на отложенной выборке!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993980388744\n"
     ]
    }
   ],
   "source": [
    "best_cls = searcher.best_estimator_\n",
    "\n",
    "print(scorer(best_cls, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы можем заметить, кроссвалидация дает достаточно точную оценку качества на обучающем множестве :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
